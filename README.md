# GaborNet

This research on deep convolutional neural networks proposes a modified architecture that focuses on improving 
convergence and reducing training complexity. The filters in the first layer of network are constrained to fit the 
Gabor function. The parameters of Gabor functions are learnable and updated by standard backpropagation techniques. 
The proposed architecture was tested on several datasets and outperformed the common convolutional networks
